{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13 Exercise - Transformers\n",
    "\n",
    "In this notebook, we will explore the creation of a Transformer Network for English to French translation.  Note that **Transformers are resource intensive and hard to train.** You will want to run these notebooks on a machine equipped with a GPU or on [Google Colab](http://colab.research.google.com).\n",
    "\n",
    "To begin, let's import a corpus of paired English and French text.  Additionally, we'll tokenize the words (i.e. create a dictionary for each vocabulary associating every word with an integer index).  There is no need to modify this cell, but have a look at what is contained in fr_to_ix (for example) and in enlines.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\" \n",
    "\n",
    "with open('./french.txt', encoding=\"utf-8\") as file:\n",
    "    frvocab = file.read().lower()\n",
    "    frvocab = ''.join([i if ord(i) < 128 else ' ' for i in frvocab])\n",
    "    frlines = frvocab.split('\\n')\n",
    "frlines = [re.sub(r'[^\\w\\s\\']','',i).split() for i in frlines]\n",
    "frvocab = set(re.sub(r'[^\\w\\s\\']','',frvocab).replace('\\n',' ').split(' '))\n",
    "\n",
    "with open('./english.txt', encoding=\"utf-8\") as file:\n",
    "    envocab = file.read().lower()\n",
    "    envocab = ''.join([i if ord(i) < 128 else '' for i in envocab])\n",
    "    enlines = envocab.split('\\n')\n",
    "enlines = [re.sub(r'[^\\w\\s]','',i).split() for i in enlines]\n",
    "envocab = set(re.sub(r'[^\\w\\s]','',envocab).replace('\\n',' ').strip().split(' '))\n",
    "envocab.add('<pad>')\n",
    "envocab.add('<start>')\n",
    "envocab.add('<eos>')\n",
    "frvocab.add('<pad>')\n",
    "frvocab.add('<start>')\n",
    "frvocab.add('<eos>')\n",
    "fr_to_ix = {word: i for i, word in enumerate(frvocab)}\n",
    "en_to_ix = {word: i for i, word in enumerate(envocab)}\n",
    "ix_to_fr = {fr_to_ix[word]:word for word in frvocab}\n",
    "ix_to_en = {en_to_ix[word]:word for word in envocab}\n",
    "enmax = 0\n",
    "frmax = 16\n",
    "\n",
    "for i,w in enumerate(enlines):\n",
    "    temp = len(w)\n",
    "    if temp > enmax:\n",
    "        enmax = temp\n",
    "\n",
    "for i,w in enumerate(frlines):\n",
    "    temp = len(w)\n",
    "    if temp > frmax:\n",
    "        frmax = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a handful of helper functions that do things like\n",
    " - Tokenize an english string, run it through the transformer producing predictions, then convert back to a french string\n",
    " - Compare predicted and target output\n",
    " - Mask a string\n",
    " - Load paired english/french sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    # Read in an english string\n",
    "    line = re.sub(r'[^\\w\\s]','',sentence).split()\n",
    "    # tokenize/pad for consistent sequence length\n",
    "    line = F.pad(torch.tensor([en_to_ix[w.lower()] for w in line]),(0,enmax-len(line)),value = en_to_ix['<pad>']).unsqueeze(0).to(device)\n",
    "    # Create an array to hold the French sentence\n",
    "    target = torch.Tensor(1,frmax-1)\n",
    "    target = target.new_full((1,frmax-1),fr_to_ix['<pad>']).long().to(device)\n",
    "    # Start sentence with a <start> character\n",
    "    target[0,0] = fr_to_ix['<start>']\n",
    "    \n",
    "    src,trg = mask(line,target)\n",
    "    encoding = model.encode(line,src)\n",
    "    K,V = model.create_dec_KV(encoding)\n",
    "    for i in range(1,frmax-1):\n",
    "        test2 = model.decode(target,K,V,src,trg)\n",
    "        lastout = test2[0,i-1].argmax()\n",
    "        if lastout.item() == fr_to_ix['<eos>']:\n",
    "            break\n",
    "        target[0,i] = lastout\n",
    "        src,trg = mask(line,target)\n",
    "    translation = test2.argmax(2).squeeze(0)\n",
    "    translation_string = ''\n",
    "    for w in translation:\n",
    "        if ix_to_fr[w.item()] == '<eos>':\n",
    "            break\n",
    "        translation_string += ix_to_fr[w.item()] + ' '\n",
    "    return translation_string.strip()\n",
    "\n",
    "def compareoutput(preds,targetlist,loc=None):\n",
    "    # Compare model predictions with true translation\n",
    "    if loc is None:\n",
    "        loc = np.random.randint(len(preds))\n",
    "    predstr = ''\n",
    "    labelstr = ''\n",
    "    for i in range(len(preds[loc][0])):\n",
    "        if ix_to_fr[targetlist[loc][i+1].item()] == '<eos>':\n",
    "            break\n",
    "        predstr += ' '+ ix_to_fr[preds[loc][0][i].item()]\n",
    "        labelstr += ' ' + ix_to_fr[targetlist[loc][i+1].item()]\n",
    "    print(\"\\tOutput:\", predstr)\n",
    "    print(\"\\tTarget:\",labelstr)\n",
    "    \n",
    "class PositionalEncoder(nn.Module):\n",
    "    # Create a positional encoding generator\n",
    "    def __init__(self, d_model, max_seq_len = 58):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "            for i in range(1,d_model,2):\n",
    "                pe[pos, i] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "        pe = pe\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:seq_len], \\\n",
    "        requires_grad=False).to(device)\n",
    "        return x\n",
    "\n",
    "def mask(input_seq,target_seq):\n",
    "    input_msk = (input_seq != en_to_ix['<pad>']).unsqueeze(1)\n",
    "    target_msk = (target_seq != fr_to_ix['<pad>']).unsqueeze(1)\n",
    "    size = target_seq.size(1) # get seq_len for matrix\n",
    "    nopeak_mask = np.triu(np.ones((1, size, size)),k=1)\n",
    "    nopeak_mask = Variable(torch.from_numpy(nopeak_mask).to(device) == 0)\n",
    "    target_msk = target_msk & nopeak_mask\n",
    "    return input_msk,target_msk\n",
    "\n",
    "class custdata(Dataset):\n",
    "    # Create a custom dataset object to serve up paired english and french lines\n",
    "    def __init__(self,enlines,frlines):\n",
    "        self.data_len = len(enlines) \n",
    "        self.data = [F.pad(torch.tensor([en_to_ix[w] for w in line]),(0,enmax-len(line)),value = en_to_ix['<pad>']).to(device) for line in enlines]\n",
    "        self.labels = []\n",
    "        for line in frlines:\n",
    "            line = ['<start>',*line,'<eos>']\n",
    "            self.labels.append(F.pad(torch.tensor([fr_to_ix[w] for w in line]),(0,frmax-len(line)),value = fr_to_ix['<pad>']).to(device))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i],self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "The first task is to code a self-attention mechanism, which corresponds to implementing Eq. 1 in Vaswani.\n",
    "#### http://jalammar.github.io/illustrated-transformer/ is a great reference for most of the programming in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_attention(nn.Module):\n",
    "    def __init__(self,dim,enc_dim,dropout = .1):\n",
    "        super().__init__()\n",
    "        self.wq = torch.nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR Q, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wk = torch.nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR K, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wv = torch.nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR V, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scaler = np.sqrt(enc_dim)\n",
    "    \n",
    "    def QKV(self,x):\n",
    "        Q = self.wq(x)  #### TODO#### CALCULATE Q\n",
    "        K = self.wk(x)  #### TODO#### CALCULATE K\n",
    "        V = self.wv(x)  #### TODO#### CALCULATE V\n",
    "        return Q,K,V\n",
    "    \n",
    "    def score(self,Q,K,V,mask):\n",
    "        # scores are the stuff that goes inside the softmax\n",
    "        scores = Q@K.T.permute(2,0,1)/self.scaler ### TODO ### CALCULATE THE SCORES. !!!DONT TOUCH THE PERMUTE!!!\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = self.dropout(F.softmax(scores,-1)) \n",
    "        return scores@V ### TODO ### FINISH CALCULATING SELF ATTENTION\n",
    "    \n",
    "    def forward(self,x,mask=None):\n",
    "        Q,K,V = self.QKV(x)\n",
    "        return self.score(Q,K,V,mask)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to produce the \"special\" attention mechanism that takes keys and values from the encoder, but queries from the decoder.  This is very similar to the self-attention mechanism, except that there should be two inputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encdec_attention(nn.Module):\n",
    "    def __init__(self,dim, dropout = .1):\n",
    "        super().__init__()\n",
    "        self.wq = torch.nn.Linear(dim, dim)  #### TODO #### SAME AS ABOVE\n",
    "        self.wk = torch.nn.Linear(dim, dim)  #### TODO #### SAME AS ABOVE\n",
    "        self.wv = torch.nn.Linear(dim, dim)  #### TODO #### SAME AS ABOVE\n",
    "        self.scaler = np.sqrt(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def Q(self,x):\n",
    "        return self.wq(x)\n",
    "    \n",
    "    def score(self,Q,K,V,mask):\n",
    "        scores = Q@K.T.permute(2,0,1)/self.scaler #### TODO #### SAME AS ABOVE\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = self.dropout(F.softmax(scores,-1)) \n",
    "        return scores@V  #### TODO #### SAME AS ABOVE\n",
    "    \n",
    "    def forward(self,x,K,V,mask):\n",
    "        # DB Note: I'm not sure that this signature is right.  Seems like we should be taking x from the\n",
    "        # decoder, as well as another argument (call it y?) from the encoder, then producing K,V,Q internally,\n",
    "        # just like in the self-attention scheme.  Otherwise, how are wk and wv being used here?  it looks like \n",
    "        # these parameters have been shifted over to the Transformer module's create_dec_KV method.\n",
    "        Q = self.Q(x)\n",
    "        out = self.score(Q,K,V,mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder and Decoder\n",
    "With the attention mechanisms coded, now we need to create encoder and decoder models. These correspond to the things inside the boxes in Figure 1 of Vaswani.  \n",
    "#### Fill in the forward passes of the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self,dim,enc_dim,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.enc_dim = enc_dim\n",
    "        self.residual = nn.Linear(dim,enc_dim)\n",
    "        \n",
    "        self.attention = self_attention(dim,enc_dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(enc_dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(enc_dim,enc_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(enc_dim)\n",
    "    \n",
    "    def forward(self,x,mask):  #### TODO #### SET UP FORWARD PASS OF ENCODER\n",
    "        atten = self.attention.forward(x, mask)\n",
    "        if self.dim != self.enc_dim: ### DONT TOUCH, THIS IS TO HELP WITH THE RESIDUAL CONNECTION ###\n",
    "            x = self.residual(x)\n",
    "        x = self.norm1(x+atten)\n",
    "        x = self.linear(x)\n",
    "        return self.norm2(x)\n",
    "     \n",
    "        \n",
    "class decoder(nn.Module):\n",
    "    def __init__(self,dim,input_size,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.attention = self_attention(input_size,dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.EDattention = encdec_attention(dim,dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(dim,dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self,x,k,v,enc_mask,dec_mask):#### TODO #### SET UP FORWARD PASS OF DECODER\n",
    "        \n",
    "        atten = self.attention.forward(x, dec_mask)\n",
    "        x = self.norm1(x+atten)\n",
    "        atten2 = self.EDattention.forward(x, k , v, enc_mask)\n",
    "        x = self.norm2(x + atten2)\n",
    "        x = self.linear(x)\n",
    "        return self.norm3(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "Build the transformer itself by hooking together encoders and decoders.  Note the word embedding layers that we are going to learn.  \n",
    "\n",
    "#### Add encoders and decoders to transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer(nn.Module):\n",
    "    def __init__(self,dim,encoder_dim,enc_vocab_size,dec_vocab_size,input_size):\n",
    "        super().__init__()\n",
    "        self.embedding1 = nn.Embedding(enc_vocab_size,dim)\n",
    "        self.embedding2 = nn.Embedding(dec_vocab_size,encoder_dim)\n",
    "        \n",
    "        self.pe1 = PositionalEncoder(dim,enmax)\n",
    "        self.pe2 = PositionalEncoder(encoder_dim,frmax)\n",
    "        self.encoders = []\n",
    "    \n",
    "        self.encoders.append(encoder(dim,encoder_dim,enc_vocab_size)) #### TODO #### ADD DESIRED # OF ENCODERS TO SELF.ENCODERS\n",
    "        \n",
    "        \n",
    "        self.encoders = nn.ModuleList(self.encoders)\n",
    "        \n",
    "        self.decoders = []\n",
    "        \n",
    "        \n",
    "        self.decoders.append(decoder(encoder_dim,encoder_dim,dec_vocab_size)) #### TODO #### ADD DESIRED # OF DECODERS TO SELF.DECODERS\n",
    "\n",
    "       \n",
    "        self.decoders = nn.ModuleList(self.decoders)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(encoder_dim,dec_vocab_size),\n",
    "            nn.LogSoftmax(2)\n",
    "        )\n",
    "        \n",
    "        self.k = nn.Linear(encoder_dim,encoder_dim)\n",
    "        self.v = nn.Linear(encoder_dim,encoder_dim)\n",
    "    def create_dec_KV(self,z):\n",
    "        K = self.k(z)\n",
    "        V = self.v(z)\n",
    "        return K,V\n",
    "    \n",
    "    def encode(self,x,src):\n",
    "        x = self.embedding1(x)\n",
    "        x = self.pe1(x)\n",
    "        for layer in self.encoders:\n",
    "            x = layer(x,src)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,y,K,V,src,trg):\n",
    "        y = self.embedding2(y)\n",
    "        y = self.pe2(y)\n",
    "        for layer in self.decoders:\n",
    "            y = layer(y,K,V,src,trg)\n",
    "        return self.final(y)\n",
    "    \n",
    "    def forward(self,x,y,src,trg):\n",
    "        \n",
    "        x = self.encode(x,src)\n",
    "        K,V = self.create_dec_KV(x)\n",
    "        y = self.decode(y,K,V,src,trg)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network.\n",
    "\n",
    "##### This will be slow to train and require a lot of resources. You can reduce the batch_size to lower the vram requirement, you can reduce \n",
    "##### the run time by lowering number_of_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer(enmax,enmax,len(envocab),len(frvocab),frmax)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01,weight_decay=.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=.1,patience=10,threshold=1,min_lr=.0001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUMBER_OF_LINES = 20000\n",
    "\n",
    "train = custdata(enlines[:NUMBER_OF_LINES],frlines[:NUMBER_OF_LINES])\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val = custdata(enlines[NUMBER_OF_LINES:NUMBER_OF_LINES+1000],frlines[NUMBER_OF_LINES:NUMBER_OF_LINES+1000])\n",
    "valloader = torch.utils.data.DataLoader(dataset=val, batch_size=1, shuffle=True, drop_last=False)\n",
    "test = custdata(enlines[NUMBER_OF_LINES+1000:NUMBER_OF_LINES+2000],frlines[NUMBER_OF_LINES+1000:NUMBER_OF_LINES+2000])\n",
    "testloader = torch.utils.data.DataLoader(dataset=test, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  loss: 121.621402323246\n",
      "\tOutput:  vous <eos> <eos>\n",
      "\tTarget:  pourquoi l'avezvous fait\n",
      "Epoch: 2  loss: 55.203126192092896\n",
      "\tOutput:  vous un <eos> vie t\n",
      "\tTarget:  c'est toi la ma tresse\n",
      "Epoch: 3  loss: 46.13878574967384\n",
      "\tOutput:  tu tes trop <eos>\n",
      "\tTarget:  vous tes trop maigrichonne\n",
      "Epoch: 4  loss: 40.41828794777393\n",
      "\tOutput:  vous besoin\n",
      "\tTarget:  l'astu invit\n",
      "Epoch: 5  loss: 35.76242959499359\n",
      "\tOutput:  vous tes tr contrari e\n",
      "\tTarget:  vous tes fort contrari s\n",
      "Epoch: 6  loss: 32.18908354640007\n",
      "\tOutput:  vous ne peux pas <eos>\n",
      "\tTarget:  tu ne peux pas m'aider\n",
      "Epoch: 7  loss: 29.548285022377968\n",
      "\tOutput:  qui a cette voiture\n",
      "\tTarget:  qui est cette voiture\n",
      "Epoch: 8  loss: 27.790898710489273\n",
      "\tOutput:  vous peux aider\n",
      "\tTarget:  tu pourrais m'aider\n",
      "Epoch: 9  loss: 26.41627550125122\n",
      "\tOutput:  voici p est meilleure\n",
      "\tTarget:  ton temps est coul\n",
      "Epoch: 10  loss: 25.31638142466545\n",
      "\tOutput:  pourquoi estce <eos> coup\n",
      "\tTarget:  pourquoi encourir le risque\n",
      "Epoch: 11  loss: 24.32097391039133\n",
      "\tOutput:  personne astu termin t <eos>\n",
      "\tTarget:  en astu bient t fini\n",
      "Epoch: 12  loss: 18.510953180491924\n",
      "\tOutput:  tu peux nous les deux\n",
      "\tTarget:  tu peux avoir les deux\n",
      "Epoch: 13  loss: 16.273682981729507\n",
      "\tOutput:  suivez son c\n",
      "\tTarget:  suivez son exemple\n",
      "Epoch: 14  loss: 15.2236957103014\n",
      "\tOutput:  ne dites pas trop\n",
      "\tTarget:  n'en dis pas trop\n",
      "Epoch: 15  loss: 14.499682448804379\n",
      "\tOutput:  ne sois pas de risqu\n",
      "\tTarget:  ne sois pas si modeste\n",
      "Epoch: 16  loss: 13.960737653076649\n",
      "\tOutput:  tu es fout des\n",
      "\tTarget:  tu me fais peur\n",
      "Epoch: 17  loss: 13.535984642803669\n",
      "\tOutput:  vous tes tous folles\n",
      "\tTarget:  vous tes toutes malades\n",
      "Epoch: 18  loss: 13.146189667284489\n",
      "\tOutput:  tu es la plus\n",
      "\tTarget:  tu es le doyen\n",
      "Epoch: 19  loss: 12.807913579046726\n",
      "\tOutput:  elles satisfait <eos>\n",
      "\tTarget:  sontelles content es\n",
      "Epoch: 20  loss: 12.558601148426533\n",
      "\tOutput:  tu grossier la toit sc\n",
      "\tTarget:  c'est toi le ma tre\n",
      "Epoch: 21  loss: 12.19293600320816\n",
      "\tOutput:  vous es d truit t\n",
      "\tTarget:  tu es d go tante\n",
      "Epoch: 22  loss: 12.022470273077488\n",
      "\tOutput:  tesvous content ici\n",
      "\tTarget:  estu heureuse ici\n",
      "Epoch: 23  loss: 10.938690025359392\n",
      "\tOutput:  peuxtu me joindre\n",
      "\tTarget:  pouvezvous me pardonner\n",
      "Epoch: 24  loss: 10.917181376367807\n",
      "\tOutput:  appelle sont quelqu'un\n",
      "\tTarget:  rappelle tes chiens\n",
      "Epoch: 25  loss: 10.892973057925701\n",
      "\tOutput:  buvez ton lait\n",
      "\tTarget:  finis ton lait\n",
      "Epoch: 26  loss: 10.788669053465128\n",
      "\tOutput:  pourquoi cette fait <eos>\n",
      "\tTarget:  pourquoi aije fait a\n",
      "Epoch: 27  loss: 10.613738153129816\n",
      "\tOutput:  qui vous a envoy ici ici\n",
      "\tTarget:  qui vous a envoy es ici\n",
      "Epoch: 28  loss: 10.547125276178122\n",
      "\tOutput:  tesvous un blague\n",
      "\tTarget:  estu une criminelle\n",
      "Epoch: 29  loss: 10.597771551460028\n",
      "\tOutput:  tesvous un criminel\n",
      "\tTarget:  tesvous un criminel\n",
      "Epoch: 30  loss: 10.521270222961903\n",
      "\tOutput:  tous avons avons tous <eos> <eos>\n",
      "\tTarget:  nous nous sommes toutes mises debout\n",
      "Epoch: 31  loss: 10.544589806348085\n",
      "\tOutput:  ne sois pas de rire propri\n",
      "\tTarget:  ne sois pas si s lectif\n",
      "Epoch: 32  loss: 10.504624467343092\n",
      "\tOutput:  ne tais pas en\n",
      "\tTarget:  n' cris pas l'encre\n",
      "Epoch: 33  loss: 10.45227126032114\n",
      "\tOutput:  tu as mal <eos> bien\n",
      "\tTarget:  tu as bien fait tom\n",
      "Epoch: 34  loss: 10.425586603581905\n",
      "\tOutput:  aimestu cie des\n",
      "\tTarget:  appr ciezvous wagner\n",
      "Epoch: 35  loss: 10.377193935215473\n",
      "\tOutput:  tu es fort timide\n",
      "\tTarget:  tu es fort craintif\n",
      "Epoch: 36  loss: 10.357472401112318\n",
      "\tOutput:  vous ne peux pas arr ter\n",
      "\tTarget:  tu ne peux pas arr ter\n",
      "Epoch: 37  loss: 10.38201691582799\n",
      "\tOutput:  vous avez l'air en\n",
      "\tTarget:  vous avez l'air super\n",
      "Epoch: 38  loss: 10.316057547926903\n",
      "\tOutput:  vous super super\n",
      "\tTarget:  t'as t super\n",
      "Epoch: 39  loss: 10.172871209681034\n",
      "\tOutput:  comportetoi prudence <eos> paisse <eos>\n",
      "\tTarget:  la prudence est conseill e\n",
      "Epoch: 40  loss: 10.151294372975826\n",
      "\tOutput:  pourquoi estu nerv col re\n",
      "\tTarget:  pourquoi estu en col re\n",
      "Epoch: 41  loss: 10.165437206625938\n",
      "\tOutput:  tout le monde te <eos>\n",
      "\tTarget:  tout le monde t'appr cie\n",
      "Epoch: 42  loss: 10.097384337335825\n",
      "\tOutput:  tesvous v g <eos>\n",
      "\tTarget:  tesvous v g tarienne\n",
      "Epoch: 43  loss: 10.061321452260017\n",
      "\tOutput:  qui a command de la pizza\n",
      "\tTarget:  qui a command de la pizza\n",
      "Epoch: 44  loss: 10.022297382354736\n",
      "\tOutput:  tesvous un blague\n",
      "\tTarget:  estu une criminelle\n",
      "Epoch: 45  loss: 9.994068820029497\n",
      "\tOutput:  demande mon\n",
      "\tTarget:  demandelui conseil\n",
      "Epoch: 46  loss: 10.014523446559906\n",
      "\tOutput:  tout le monde tait t l\n",
      "\tTarget:  tout le monde a t vigilant\n",
      "Epoch: 47  loss: 10.033723179250956\n",
      "\tOutput:  il tetoi <eos> japon\n",
      "\tTarget:  appr cietil le japon\n",
      "Epoch: 48  loss: 9.967195458710194\n",
      "\tOutput:  je voir a\n",
      "\tTarget:  puisje voir celuici\n",
      "Epoch: 49  loss: 9.895238295197487\n",
      "\tOutput:  viens un feu\n",
      "\tTarget:  approchetoi du feu\n",
      "Epoch: 50  loss: 9.850218378007412\n",
      "\tOutput:  aimestu aimez le fais\n",
      "\tTarget:  vous aimez le sport\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for j,(context, target) in enumerate(trainloader):\n",
    "        trg_input = target[:,:-1]\n",
    "        outmask = target[:,1:]!= fr_to_ix['<pad>']\n",
    "        targets = target[:,1:].contiguous().view(-1)\n",
    "        src,trg = mask(context,trg_input)\n",
    "        output = model(context,trg_input,src,trg)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.view(output.shape[0]*output.shape[1],-1),targets)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    scheduler.step(total_loss)\n",
    "    print('Epoch:', i+1,' loss:', total_loss)\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    preds = []\n",
    "    targetlist = []\n",
    "    for j,(context, target) in enumerate(valloader):\n",
    "            trg_input = target[:,:-1]\n",
    "            targets = target.contiguous().view(-1)\n",
    "            targetlist.append(targets)\n",
    "            src,trg = mask(context,trg_input)\n",
    "            output = model(context,trg_input,src,trg)\n",
    "            pred = F.softmax(output,2).argmax(2)\n",
    "            preds.append(pred)\n",
    "            break\n",
    "    compareoutput(preds,targetlist,loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your translator\n",
    "\n",
    "##### Unless you speak french you're going have to check it with google translate https://translate.google.com/\n",
    "##### I found it started doing alright once the loss got below 10 but this might take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ce n'est pas un probl me\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'this translator does not translate'\n",
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That translates to 'it's not a problem'\n",
    "\n",
    "#### Test it on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of words correct 0.577505735930736\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "scores = []\n",
    "preds = []\n",
    "targetlist = []\n",
    "for j,(context, target) in enumerate(testloader):\n",
    "        trg_input = target[:,:-1]\n",
    "        targets = target[:,1:].contiguous().view(-1)\n",
    "        targetlist.append(targets)\n",
    "        src,trg = mask(context,trg_input)\n",
    "        output = model(context,trg_input,src,trg)\n",
    "        pred = F.softmax(output,2).argmax(2)\n",
    "        preds.append(pred)\n",
    "        correct = sum(pred[0][targets!=fr_to_ix['<pad>']]==targets[targets!=fr_to_ix['<pad>']]).item()/len(targets[targets!=fr_to_ix['<pad>']])\n",
    "        scores.append(correct)\n",
    "plt.plot(scores)\n",
    "print('Average # of words correct',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI-HEAD ATTENTION (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_attention(nn.Module):\n",
    "    def __init__(self,dim,encoder_dim,dropout = .1):\n",
    "        super().__init__()\n",
    "        \n",
    "        heads = []\n",
    "        for i in range(3): ### TODO ### CHOOSE THE # OF HEADS YOU WANT\n",
    "            heads.append(self_attention(dim, encoder_dim)) ### TODO ### ADD SELF_ATTENTION LAYERS TO HEADS\n",
    "        \n",
    "        self.heads = nn.ModuleList(heads)\n",
    "        \n",
    "        self.linear = nn.Linear(3*dim,encoder_dim) ### TODO ###\n",
    "    \n",
    "    \n",
    "    def forward(self,x,mask=None):\n",
    "        headoutputs = [layer(x,mask) for layer in self.heads]\n",
    "        headoutputs = torch.cat(headoutputs,dim=2)\n",
    "        return self.linear(headoutputs)\n",
    "    \n",
    "class encoder(nn.Module):\n",
    "    def __init__(self,dim,enc_dim,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.enc_dim = enc_dim\n",
    "        self.attention = multi_attention(dim,enc_dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(enc_dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(enc_dim,enc_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.residual = nn.Linear(dim,enc_dim)\n",
    "        self.norm2 = nn.LayerNorm(enc_dim)\n",
    "    \n",
    "    def forward(self,x,mask):\n",
    "        z = self.attention(x,mask)\n",
    "        if self.dim != self.enc_dim:\n",
    "            x = self.residual(x)\n",
    "        z = self.norm1(x+z)\n",
    "        z2 = self.linear(z)\n",
    "        return self.norm2(z+z2)\n",
    "     \n",
    "    \n",
    "class decoder(nn.Module):\n",
    "    def __init__(self,dim,input_size,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.attention = multi_attention(input_size,dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.EDattention = encdec_attention(dim,dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(dim,dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self,x,k,v,src,trg):\n",
    "        z = self.attention(x,trg)\n",
    "        z = self.norm1(z+x)\n",
    "        z2 = self.EDattention(z,k,v,src)\n",
    "        z2 = self.norm2(z2+z)\n",
    "        z3 = self.linear(z2)\n",
    "        return self.norm3(z3+z2)\n",
    "    \n",
    "class transformer(nn.Module):\n",
    "    def __init__(self,dim,encoder_dim,enc_vocab_size,dec_vocab_size,input_size):\n",
    "        super().__init__()\n",
    "        self.embedding1 = nn.Embedding(enc_vocab_size,dim)\n",
    "        self.embedding2 = nn.Embedding(dec_vocab_size,encoder_dim)\n",
    "        \n",
    "        self.pe1 = PositionalEncoder(dim,enmax)\n",
    "        self.pe2 = PositionalEncoder(encoder_dim,frmax)\n",
    "        self.encoders = []\n",
    "    \n",
    "        self.encoders.append(encoder(dim,encoder_dim,enc_vocab_size))   ### FEEL FREE TO ADD OR REMOVE ENCODERS\n",
    "        self.encoders = nn.ModuleList(self.encoders)\n",
    "        \n",
    "        self.decoders = []\n",
    "        self.decoders.append(decoder(encoder_dim,encoder_dim,dec_vocab_size)) ### FEEL FREE TO ADD OR REMOVE ENCODERS\n",
    "        self.decoders = nn.ModuleList(self.decoders)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(encoder_dim,dec_vocab_size),\n",
    "            nn.LogSoftmax(2)\n",
    "        )\n",
    "        \n",
    "        self.k = nn.Linear(encoder_dim,encoder_dim)\n",
    "        self.v = nn.Linear(encoder_dim,encoder_dim)\n",
    "        \n",
    "    def create_dec_KV(self,z):\n",
    "        K = self.k(z)\n",
    "        V = self.v(z)\n",
    "        return K,V\n",
    "    \n",
    "    def encode(self,x,src):\n",
    "        x = self.embedding1(x)\n",
    "        x = self.pe1(x)\n",
    "        for layer in self.encoders:\n",
    "            x = layer(x,src)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,y,K,V,src,trg):\n",
    "        y = self.embedding2(y)\n",
    "        y = self.pe2(y)\n",
    "        for layer in self.decoders:\n",
    "            y = layer(y,K,V,src,trg)\n",
    "        return self.final(y)\n",
    "        \n",
    "    \n",
    "    def forward(self,x,y,src,trg):\n",
    "        x = self.encode(x,src)\n",
    "        K,V = self.create_dec_KV(x)\n",
    "        y = self.decode(y,K,V,src,trg)\n",
    "        \n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer(enmax,enmax,len(envocab),len(frvocab),frmax)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01,weight_decay=.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=.1,patience=10,threshold=1,min_lr=.0001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  loss: 113.80207216739655\n",
      "\tOutput:  tu tes fort <eos>\n",
      "\tTarget:  vous tes fort riches\n",
      "Epoch: 2  loss: 52.80080381035805\n",
      "\tOutput:  elles une la chance\n",
      "\tTarget:  avezvous de la monnaie\n",
      "Epoch: 3  loss: 42.93676906824112\n",
      "\tOutput:  vous le faire\n",
      "\tTarget:  peuxtu le croire\n",
      "Epoch: 4  loss: 36.18599784374237\n",
      "\tOutput:  je y <eos>\n",
      "\tTarget:  puisje voir celuici\n",
      "Epoch: 5  loss: 31.05963760614395\n",
      "\tOutput:  vous es raison raison\n",
      "\tTarget:  tu as moiti raison\n",
      "Epoch: 6  loss: 27.58588269352913\n",
      "\tOutput:  vous es mort <eos>\n",
      "\tTarget:  tu aurais pu mourir\n",
      "Epoch: 7  loss: 25.304759606719017\n",
      "\tOutput:  venez de si <eos> p libataires\n",
      "\tTarget:  viens et assiedstoi mon c t\n",
      "Epoch: 8  loss: 23.729938961565495\n",
      "\tOutput:  vous seules ici\n",
      "\tTarget:  tesvous seuls ici\n",
      "Epoch: 9  loss: 22.5458881855011\n",
      "\tOutput:  j'ai crit\n",
      "\tTarget:  l'aije mentionn\n",
      "Epoch: 10  loss: 21.552936665713787\n",
      "\tOutput:  tesvous heureux ici\n",
      "\tTarget:  tesvous heureuse ici\n",
      "Epoch: 11  loss: 20.9642721042037\n",
      "\tOutput:  tu tes fort contrari\n",
      "\tTarget:  vous tes fort contrari\n",
      "Epoch: 12  loss: 14.791982784867287\n",
      "\tOutput:  commen commen commen train commen ons\n",
      "\tTarget:  quoi qu'il en soit commen ons\n",
      "Epoch: 13  loss: 12.405568227171898\n",
      "\tOutput:  tu <eos> <eos>\n",
      "\tTarget:  vastu t'en servir\n",
      "Epoch: 14  loss: 11.41252500936389\n",
      "\tOutput:  puisje l'emprunter du ler\n",
      "\tTarget:  puisje louer des raquettes\n",
      "Epoch: 15  loss: 10.706048011779785\n",
      "\tOutput:  tu tes avez\n",
      "\tTarget:  vous me tuez\n",
      "Epoch: 16  loss: 10.118285834789276\n",
      "\tOutput:  vous sentezvous mieux <eos> dormir\n",
      "\tTarget:  vous feriez mieux de venir\n",
      "Epoch: 17  loss: 9.779719077050686\n",
      "\tOutput:  quiconque vu <eos> <eos> ce soit\n",
      "\tTarget:  astu vu qui que ce soit\n",
      "Epoch: 18  loss: 9.431267455220222\n",
      "\tOutput:  il de tait crev avoir\n",
      "\tTarget:  hier il a fait chaud\n",
      "Epoch: 19  loss: 9.151802062988281\n",
      "\tOutput:  vous tes tr timide\n",
      "\tTarget:  vous tes fort timides\n",
      "Epoch: 20  loss: 8.970553778111935\n",
      "\tOutput:  tu un femme\n",
      "\tTarget:  tesvous une criminelle\n",
      "Epoch: 21  loss: 8.723502937704325\n",
      "\tOutput:  vous es malpoli\n",
      "\tTarget:  tu es productive\n",
      "Epoch: 22  loss: 8.556619241833687\n",
      "\tOutput:  apprends avais <eos>\n",
      "\tTarget:  tu apprends rapidement\n",
      "Epoch: 23  loss: 7.608167212456465\n",
      "\tOutput:  vous es perdu la partie\n",
      "\tTarget:  tu as perdu la partie\n",
      "Epoch: 24  loss: 7.47756078094244\n",
      "\tOutput:  buvez ton lait\n",
      "\tTarget:  finis ton lait\n",
      "Epoch: 25  loss: 7.384740632027388\n",
      "\tOutput:  fais comme il te plaira\n",
      "\tTarget:  fais comme il te dit\n",
      "Epoch: 26  loss: 7.364501502364874\n",
      "\tOutput:  tout le monde est fait\n",
      "\tTarget:  tout le monde a peur\n",
      "Epoch: 27  loss: 7.391729559749365\n",
      "\tOutput:  je aije fait\n",
      "\tTarget:  vous aije surpris\n",
      "Epoch: 28  loss: 7.304943557828665\n",
      "\tOutput:  tesvous int tesvous e\n",
      "\tTarget:  tesvous int ress s\n",
      "Epoch: 29  loss: 7.295816693454981\n",
      "\tOutput:  puisje l'emprunter <eos> tien\n",
      "\tTarget:  puisje emprunter le tien\n",
      "Epoch: 30  loss: 7.232234887778759\n",
      "\tOutput:  reste moment est facile <eos> <eos> facile <eos>\n",
      "\tTarget:  ce qui est facilement gagn est facilement perdu\n",
      "Epoch: 31  loss: 7.226591471582651\n",
      "\tOutput:  vous tes trop maigrichonne\n",
      "\tTarget:  vous tes trop maigrichon\n",
      "Epoch: 32  loss: 7.173447411507368\n",
      "\tOutput:  vous es trop maigrichonne\n",
      "\tTarget:  tu es trop maigrichon\n",
      "Epoch: 33  loss: 7.169018521904945\n",
      "\tOutput:  tu tes affaires <eos> aller\n",
      "\tTarget:  vous tes libre d'y aller\n",
      "Epoch: 34  loss: 7.111443117260933\n",
      "\tOutput:  avezvous demand\n",
      "\tTarget:  l'astu invit\n",
      "Epoch: 35  loss: 7.004301052540541\n",
      "\tOutput:  tu cours de s vite\n",
      "\tTarget:  tu cours tr s rapidement\n",
      "Epoch: 36  loss: 7.088992599397898\n",
      "\tOutput:  pourquoi estu seul\n",
      "\tTarget:  pourquoi estu seul\n",
      "Epoch: 37  loss: 7.065096773207188\n",
      "\tOutput:  il cie de chine\n",
      "\tTarget:  appr cietil la chine\n",
      "Epoch: 38  loss: 7.031999837607145\n",
      "\tOutput:  a es perdu la partie\n",
      "\tTarget:  tu as perdu la partie\n",
      "Epoch: 39  loss: 7.003137703984976\n",
      "\tOutput:  il as besoin de dormir\n",
      "\tTarget:  tu as besoin de dormir\n",
      "Epoch: 40  loss: 6.911101963371038\n",
      "\tOutput:  aimestu les recyclage\n",
      "\tTarget:  aimestu le saumon\n",
      "Epoch: 41  loss: 6.894286174327135\n",
      "\tOutput:  vous tes talentueuse\n",
      "\tTarget:  vous tes cern\n",
      "Epoch: 42  loss: 6.842846393585205\n",
      "\tOutput:  veuxtu une tu vous le ne\n",
      "\tTarget:  voulezvous que je vous emm ne\n",
      "Epoch: 43  loss: 6.8688955791294575\n",
      "\tOutput:  vous senstu coupable\n",
      "\tTarget:  te senstu coupable\n",
      "Epoch: 44  loss: 6.853998750448227\n",
      "\tOutput:  tu n'es pas normal\n",
      "\tTarget:  tu n'es pas normal\n",
      "Epoch: 45  loss: 6.791526760905981\n",
      "\tOutput:  assiedstoi le monde se\n",
      "\tTarget:  tout le monde paniqua\n",
      "Epoch: 46  loss: 6.836123418062925\n",
      "\tOutput:  tu devez me devez tendstoi\n",
      "\tTarget:  vous devez vous d tendre\n",
      "Epoch: 47  loss: 6.76790976524353\n",
      "\tOutput:  tesvous int tesvous e\n",
      "\tTarget:  tesvous int ress e\n",
      "Epoch: 48  loss: 6.702316842973232\n",
      "\tOutput:  estu es enseignant\n",
      "\tTarget:  tu es enseignant\n",
      "Epoch: 49  loss: 6.683687083423138\n",
      "\tOutput:  qui a fait a chose\n",
      "\tTarget:  qui a fait cette tourte\n",
      "Epoch: 50  loss: 6.662153258919716\n",
      "\tOutput:  estce que je te m v\n",
      "\tTarget:  estce que je vous d range\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for j,(context, target) in enumerate(trainloader):\n",
    "        trg_input = target[:,:-1]\n",
    "        outmask = target[:,1:]!= fr_to_ix['<pad>']\n",
    "        targets = target[:,1:].contiguous().view(-1)\n",
    "        src,trg = mask(context,trg_input)\n",
    "        output = model(context,trg_input,src,trg)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.view(output.shape[0]*output.shape[1],-1),targets)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    scheduler.step(total_loss)\n",
    "    print('Epoch:', i+1,' loss:', total_loss)\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    preds = []\n",
    "    targetlist = []\n",
    "    for j,(context, target) in enumerate(valloader):\n",
    "            trg_input = target[:,:-1]\n",
    "            targets = target.contiguous().view(-1)\n",
    "            targetlist.append(targets)\n",
    "            src,trg = mask(context,trg_input)\n",
    "            output = model(context,trg_input,src,trg)\n",
    "            pred = F.softmax(output,2).argmax(2)\n",
    "            preds.append(pred)\n",
    "            break\n",
    "    compareoutput(preds,targetlist,loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your  multi-head transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ce n'est pas du probl me\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'this translator does not translate'\n",
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION\n",
    "\n",
    "#### 1) Was the runtime of your multi-head transformer noticably longer than the single head one? What about the speed the loss decreased? If you had the time and resources to train it to a good spot, how did the translation quality compare to the single-headed transformer?\n",
    "\n",
    "The multiheaded network, was a bit slower, and had similar losses, with a little faster loss decrease. The translation quality output is considerably better (see training outputs), although, it is still trying to convince me that it's inability to translate my example sentence is not a problem. \n",
    "\n",
    "#### 2)Try adding encoders and decoders to one of your transformers. Does having the extra layers improve performance? How does it affect runtime?\n",
    "\n",
    "Did not have time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
